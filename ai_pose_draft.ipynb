{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and import Depenedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting video feed\n",
    "## number represents webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## opening up feed\n",
    "while cap.isOpened():\n",
    "    # preparing capture feed and show it!\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow(\"mediapipe feed\", frame)\n",
    "\n",
    "    ## closes if we close the screen or hit q button\n",
    "    if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "        break\n",
    "# destroys video feed\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make detections with available webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting video feed\n",
    "## number represents webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "## Context manager to define model and mode of detection . Min detection confidence and tracking confidence -> more accurate moodel increase metrics!\n",
    "with mp_pose.Pose(min_detection_confidence =0.5, min_tracking_confidence=0.5) as pose:\n",
    "    ## opening up feed \n",
    "    while cap.isOpened():\n",
    "        # preparing capture feed and show it!\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB. Original feed in openCV is BGR! Therefore we need to re-order and put it into mediapipe\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable= False ## -> memory saving\n",
    "\n",
    "        # Making detection of the image as inference\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolouring back image to BGR for openCV\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR) ## --> covert back from mediapipe RGB to openCV BGR so that we can ask openCV to display the results\n",
    "\n",
    "        # Rendering detections on screen . results.pose_landmarks has points of where the landmarks are. mp_pose.POSE_CONNECTIONS shows the pose points that connections are.\n",
    "        # whats this doing? Its first taking our image in np.array format, we then pass in our landmarks list(in this case the results). first mp_drawing spec is the circles and 2nd is the connection spec, the lines!\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2))\n",
    "\n",
    "        cv2.imshow(\"mediapipe feed\", image)\n",
    "\n",
    "        ## closes if we close the screen or hit q button\n",
    "        if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "# destroys video feed\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determing Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit ('ai_pose')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "590564a72372105222fb8d6d8e790af826110e70e73c622413f5062395d2fe5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
